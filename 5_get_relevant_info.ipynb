{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics analysis\n",
    "\n",
    "This script gets valuable information from the calculated metrics. Detect possible relevant words and determine their contribution for each group of results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14.4, 10.8]\n",
    "plt.rcParams['figure.dpi'] = 200 # 200 e.g. is really fine, but slower\n",
    "\n",
    "CHECKPOINT = 'bert-base-multilingual-cased'\n",
    "FOLDER = './outputs/DS1/bert-base-multilingual-cased'\n",
    "\n",
    "# Create a \"words\" folder to save relevant words\n",
    "Path(f'{FOLDER}/words/').mkdir(parents=True, exist_ok=True)\n",
    "Path(f'{FOLDER}/graphics/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOP_N = 30\n",
    "\n",
    "TOPS = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "R_W_COLORS = [\n",
    "    '#2d93ad',\n",
    "    '#ff6978',\n",
    "]\n",
    "\n",
    "GROUPS = [\n",
    "    'antichina',\n",
    "    'antivacina',\n",
    "    'provacina'\n",
    "]\n",
    "\n",
    "GROUPS_NAMES = {\n",
    "    'antichina': 'Anti-sinovaxxers',\n",
    "    'antivacina': 'Anti-vaxxers',\n",
    "    'provacina': 'Pro-vaxxers',\n",
    "}\n",
    "\n",
    "COUNTS = {}\n",
    "for i, row in pd.read_csv(f'{FOLDER}/result_counts.csv').iterrows():\n",
    "    COUNTS[row['name']] = row['count']\n",
    "print(COUNTS)\n",
    "\n",
    "words_metrics = pd.read_csv(f'{FOLDER}/words_metrics.csv')\n",
    "words_metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Words with greatest attention (in general)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PROPORTION = (\n",
    "    (\n",
    "        COUNTS['antichina_correct'] +\\\n",
    "        COUNTS['antivacina_correct'] +\\\n",
    "        COUNTS['provacina_correct']\n",
    "    ) /\\\n",
    "    COUNTS['total']\n",
    ")\n",
    "\n",
    "fig, axes= plt.subplots(1, 1, figsize=(8, 8))\n",
    "fig.subplots_adjust(wspace=0.35)\n",
    "\n",
    "axes.set_xlabel('Absolute attention')\n",
    "# axarr[1].set_xlabel('Relative attention')\n",
    "\n",
    "absolute_df = words_metrics.sort_values('absolute', ascending=False).head(TOP_N)\n",
    "absolute_df.plot(kind='barh', ax=axes, x='word', y=['absolute_correct', 'absolute_incorrect'], title='Top 30 words with greatest absolute attention', color=[R_W_COLORS[0], R_W_COLORS[1]], stacked=True, legend=None, xlabel='Word')\n",
    "bar = 0\n",
    "thresholds = 0\n",
    "for _, row in absolute_df.iterrows():\n",
    "    if row['absolute_correct'] < PROPORTION * row['absolute']:\n",
    "        if thresholds == 0:\n",
    "            axes.axvline(PROPORTION * row['absolute'], (bar / TOP_N), ((bar + 1)/TOP_N), color='black', linestyle='--', label='aa')\n",
    "            thresholds += 1\n",
    "        else:\n",
    "            axes.axvline(PROPORTION * row['absolute'], (bar / TOP_N), ((bar + 1)/TOP_N), color='black', linestyle='--')\n",
    "    bar += 1\n",
    "handles, _ = axes.get_legend_handles_labels()\n",
    "axes.legend(handles[1:] + [handles[0]], ['Attention on well-predicted tweets', 'Attention on mispredicted tweets', 'Threshold for misprediction contribution'])\n",
    "\n",
    "fig.savefig(f'{FOLDER}/graphics/general.svg', format='svg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Words with greatest attention (by group)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TOP_N = 20\n",
    "\n",
    "fig, axarr = plt.subplots(1, 3, figsize=(14.4, 6.5))\n",
    "\n",
    "for i, group in enumerate(GROUPS):\n",
    "    axarr[i].set_xlabel('Absolute attention')\n",
    "    \n",
    "    group_df = words_metrics.sort_values(f'{group}_absolute', ascending=False).head(TOP_N)\n",
    "    PROPORTION = COUNTS[f'{group}_correct'] / COUNTS[f'{group}']\n",
    "    \n",
    "    bar = 0\n",
    "    thresholds = 0\n",
    "    for _, row in group_df.iterrows():\n",
    "        if row[f'{group}_absolute_correct'] < PROPORTION * row[f'{group}_absolute']:\n",
    "            if thresholds == 0:\n",
    "                axarr[i].axvline(PROPORTION * row[f'{group}_absolute'], (bar / TOP_N), ((bar + 1)/TOP_N), color='black', linestyle='--', label='aa')\n",
    "                thresholds += 1\n",
    "            else:\n",
    "                axarr[i].axvline(PROPORTION * row[f'{group}_absolute'], (bar / TOP_N), ((bar + 1)/TOP_N), color='black', linestyle='--')\n",
    "        bar += 1\n",
    "    \n",
    "    group_df.plot(kind='barh', ax=axarr[i], x='word', y=[f'{group}_absolute_correct', f'{group}_absolute_incorrect'], title=GROUPS_NAMES[group], color=[R_W_COLORS[0], R_W_COLORS[1]], stacked=True, legend=None, xlabel='Word')\n",
    "    axarr[i].set_xlim(0, 15)\n",
    "    \n",
    "fig.subplots_adjust(wspace=0.45)\n",
    "fig.savefig(f'{FOLDER}/graphics/groups.svg', format='svg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) Get _relevant_, _positive-contributing_ and _existing-in-vocabulary words_..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(CHECKPOINT)\n",
    "vocab_words = list(tokenizer.vocab.keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "general_percentages = {}\n",
    "\n",
    "PROPORTION = (\n",
    "    (\n",
    "        COUNTS['antichina_correct'] +\\\n",
    "        COUNTS['antivacina_correct'] +\\\n",
    "        COUNTS['provacina_correct']\n",
    "    ) /\\\n",
    "    COUNTS['total']\n",
    ")\n",
    "\n",
    "for top in TOPS:\n",
    "    general_percentages[top] = {\n",
    "        'average_attention': 0.0,\n",
    "        'relevant': 0.0,\n",
    "        'correct': 0.0,\n",
    "        'in_vocabulary': 0.0,\n",
    "    }\n",
    "    \n",
    "    absolute_df = words_metrics.sort_values('absolute', ascending=False).head(top)\n",
    "    \n",
    "    if top == 500:\n",
    "        absolute_df.to_csv(f'./{FOLDER}/words/top_{top}_words.csv', sep=';', index=None)\n",
    "    \n",
    "    general_percentages[top]['average_attention'] = np.mean(absolute_df.absolute.values)\n",
    "    \n",
    "    tfidf = words_metrics.sort_values('tfidf', ascending=False).head(top)\n",
    "    intersection = set(absolute_df.word).intersection(set(tfidf.word))\n",
    "    pd.DataFrame({'word': list(intersection)}).to_csv(f'{FOLDER}/words/relevant_{top}.csv', index=None)\n",
    "    general_percentages[top]['relevant'] = len(intersection) / top * 100\n",
    "    \n",
    "    absolute_correct = absolute_df[absolute_df.absolute_correct >= PROPORTION * absolute_df.absolute]\n",
    "    intersection = set(absolute_df.word).intersection(set(absolute_correct.word))\n",
    "    pd.DataFrame({'word': list(intersection)}).to_csv(f'{FOLDER}/words/correct_{top}.csv', index=None)\n",
    "    general_percentages[top]['correct'] = len(intersection) / top * 100\n",
    "\n",
    "    words_present_in_vocab = 0\n",
    "    for word in list(absolute_df.word):\n",
    "        if word in vocab_words:\n",
    "            words_present_in_vocab += 1\n",
    "    general_percentages[top]['in_vocabulary'] = words_present_in_vocab / top * 100\n",
    "\n",
    "percentages_df = pd.DataFrame(general_percentages).T\n",
    "percentages_df.insert(0, column='top', value=percentages_df.index)\n",
    "percentages_df.to_csv(f'{FOLDER}/words/general_percentages.csv', index=None, sep=';')\n",
    "percentages_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Normality test:\n",
    "for metric in ['average_attention', 'correct', 'in_vocabulary']:\n",
    "    print('%s: %.4f' % (metric, stats.shapiro(percentages_df[metric].values).pvalue))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get correlations...\n",
    "print(\n",
    "    \"Corr. attention vs well-contributing: %.4f (p=%.4f)\" %\\\n",
    "    stats.spearmanr(percentages_df.average_attention.values, percentages_df.correct.values)\n",
    ")\n",
    "print(\n",
    "    \"Corr. well-contributing vs in-vocabulary: %.4f (p=%.4f)\" %\\\n",
    "    stats.spearmanr(percentages_df.correct.values, percentages_df.in_vocabulary.values)\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "group_percentages = {}\n",
    "\n",
    "for group in GROUPS:\n",
    "\n",
    "    PROPORTION = COUNTS[f'{group}_correct'] / COUNTS[f'{group}']\n",
    "    \n",
    "    for top in TOPS:\n",
    "        group_percentages[f'{group}_{top}'] = {\n",
    "            'average_attention': 0.0,\n",
    "            'relevant': 0.0,\n",
    "            'correct': 0.0,\n",
    "        }\n",
    "\n",
    "        absolute = words_metrics.sort_values(f'{group}_absolute', ascending=False).head(top)\n",
    "\n",
    "        group_percentages[f'{group}_{top}']['average_attention'] = np.mean(absolute.absolute.values)\n",
    "\n",
    "        tfidf = words_metrics.sort_values(f'{group}_tfidf', ascending=False).head(top)\n",
    "        intersection = set(absolute.word).intersection(set(tfidf.word))\n",
    "        group_percentages[f'{group}_{top}']['relevant'] = len(intersection) / top * 100\n",
    "\n",
    "        absolute_correct = absolute[absolute[f'{group}_absolute_correct'] >= PROPORTION * absolute[f'{group}_absolute']]\n",
    "\n",
    "        intersection = set(absolute_df.word).intersection(set(absolute_correct.word))\n",
    "        group_percentages[f'{group}_{top}']['correct'] = len(intersection) / top * 100\n",
    "\n",
    "percentages_df = pd.DataFrame(group_percentages).T\n",
    "percentages_df.insert(0, column='top', value=percentages_df.index)\n",
    "percentages_df.to_csv(f'{FOLDER}/words/groups_percentages.csv', index=None, sep=';')\n",
    "percentages_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get correlations...\n",
    "print(\n",
    "    \"Corr. attention vs well-contributing: %.4f (p=%.4f)\" %\\\n",
    "    stats.spearmanr(percentages_df.average_attention.values, percentages_df.correct.values)\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11804bb1f250a85d0267cdde9a53e916113451a0f88a057835fc51e3493d4141"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}